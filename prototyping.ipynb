{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd843b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import queue, threading, time\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import write as wv\n",
    "import tempfile, os\n",
    "import sounddevice as sd\n",
    "import pyttsx3\n",
    "from datetime import datetime \n",
    "import pickle \n",
    "import face_recognition\n",
    "import cv2\n",
    "from pathlib import Path \n",
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "import requests, json\n",
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3dfda41d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61ec6ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AIGuardAgent:\n",
    "    def __init__(self):\n",
    "        self.model = whisper.load_model(\"base.en\")\n",
    "        self.SAMPLE_RATE = 16000\n",
    "        self.CHUNK_SECONDS = 2\n",
    "        self.audio_queue = queue.Queue(maxsize=10)\n",
    "        \n",
    "        self.tts_engine = pyttsx3.init()\n",
    "        self.tts_engine.setProperty('rate', 150)\n",
    "        \n",
    "        self.guard_mode = False\n",
    "        self.listening = False\n",
    "        self.stop_flag = False\n",
    "        self.alarm_activated = False\n",
    "        \n",
    "        self.face_db_path = \"face_database.pkl\"\n",
    "        self.ensure_face_db_directory()\n",
    "        self.load_trusted_faces()\n",
    "        \n",
    "        # Thread safety\n",
    "        self.thread_lock = threading.Lock()\n",
    "        self.camera = None\n",
    "        self.camera_lock = threading.Lock()\n",
    "        \n",
    "        # NEW: Authority notification settings\n",
    "        self.authority_contacts = [\"security@campus.edu\"]\n",
    "        self.webhook_url = \"https://hooks.example.com/alert\"\n",
    "        \n",
    "        # Face tracking\n",
    "        self.unknown_person_tracker = {}\n",
    "        self.conversation_memory = {}\n",
    "        self.situation_context = {\n",
    "            \"time_of_day\": \"\",\n",
    "            \"last_recognized_person\": \"\",\n",
    "            \"recent_events\": []\n",
    "        }\n",
    "        \n",
    "        self.escalation_levels = {\n",
    "            1: \"polite warning\",\n",
    "            2: \"firm warning\", \n",
    "            3: \"final warning\"\n",
    "        }\n",
    "        \n",
    "        self.activation_phrases = [\n",
    "            \"guard my room\", \"protect my room\", \"secure my room\", \n",
    "            \"start guard mode\", \"activate guard\"\n",
    "        ]\n",
    "        \n",
    "        self.deactivation_phrases = [\n",
    "            \"stop guard mode\", \"deactivate guard\", \"stand down\",\n",
    "            \"stop monitoring\", \"goodbye guard\"\n",
    "        ]\n",
    "        \n",
    "        self.enrollment_phrases = [\n",
    "            \"enroll face\", \"register face\", \"add trusted person\"\n",
    "        ]\n",
    "        \n",
    "        self.current_dialog_context = \"\"\n",
    "        self.setup_llm()\n",
    "\n",
    "\n",
    "    ####################################\n",
    "    #      RESOURCE MANAGEMENT         #\n",
    "    ####################################    \n",
    "    def ensure_face_db_directory(self):\n",
    "        os.makedirs(os.path.dirname(self.face_db_path) or \".\", exist_ok=True)\n",
    "    def get_camera(self):\n",
    "        \"\"\"Access camera without threading issues\"\"\"\n",
    "        with self.camera_lock:\n",
    "            if self.camera is None or not self.camera.isOpened():\n",
    "                self.camera = cv2.VideoCapture(0)\n",
    "                if self.camera.isOpened():\n",
    "                    self.camera.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "                    self.camera.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "            return self.camera\n",
    "\n",
    "    def release_camera(self):\n",
    "        \"\"\"Safely release camera\"\"\"\n",
    "        with self.camera_lock:\n",
    "            if self.camera and self.camera.isOpened():\n",
    "                self.camera.release()\n",
    "                self.camera = None  \n",
    "    \n",
    "    def load_trusted_faces(self):\n",
    "        \"\"\"Load in trusted faces from file\"\"\"\n",
    "        try:\n",
    "            if os.path.exists(self.face_db_path):\n",
    "                with open(self.face_db_path, 'rb') as f:\n",
    "                    data = pickle.load(f)\n",
    "                    self.known_face_encodings = data['encodings']\n",
    "                    self.known_face_names = data['names']\n",
    "                print(f\"Loaded {len(self.known_face_names)} trusted faces\")\n",
    "            else:\n",
    "                print(\"No face database found. Starting fresh.\")\n",
    "                self.known_face_encodings = []\n",
    "                self.known_face_names = []\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading face database: {e}\")\n",
    "            self.known_face_encodings = []\n",
    "            self.known_face_names = []\n",
    "\n",
    "    def save_trusted_faces(self):\n",
    "        \"\"\"Save trusted faces to database\"\"\"\n",
    "        try:\n",
    "            with open(self.face_db_path, 'wb') as f:\n",
    "                pickle.dump({\n",
    "                    'encodings': self.known_face_encodings,\n",
    "                    'names': self.known_face_names\n",
    "                }, f)\n",
    "            print(f\"Saved {len(self.known_face_names)} faces to database\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving face database: {e}\")\n",
    "\n",
    "    \n",
    "\n",
    "    def _find_or_create_person_id(self,encoding):\n",
    "        \"\"\"Find existing person or create new ID\"\"\"\n",
    "        # Check if this face matches any existing unknown person\n",
    "        for person_id, data in self.unknown_person_tracker.items():\n",
    "            stored_encoding = data['reference_encoding']\n",
    "            distance = np.linalg.norm(stored_encoding - encoding)\n",
    "            if distance < 0.6:  # Similarity threshold\n",
    "                return person_id\n",
    "        \n",
    "        # New person - create ID\n",
    "        new_id = max(self.unknown_person_tracker.keys(), default=0) + 1\n",
    "        return new_id\n",
    "\n",
    "    \n",
    "    def _create_new_tracker(self, face_encoding):\n",
    "        \"\"\"Create new person tracker\"\"\"\n",
    "        return {\n",
    "            'reference_encoding': face_encoding,\n",
    "            'first_seen': time.time(),\n",
    "            'last_seen': time.time(),\n",
    "            'escalation_level': 1,\n",
    "            'response_cooldown': 30,\n",
    "            'appearances': 1,\n",
    "            'last_interaction': time.time()\n",
    "        }\n",
    "\n",
    "    def _update_person_tracking(self, person_id, face_encoding):\n",
    "        \"\"\"Update tracking and determine escalation level\"\"\"\n",
    "        if person_id not in self.unknown_person_tracker:\n",
    "            self.unknown_person_tracker[person_id] = self._create_new_tracker(face_encoding)\n",
    "            return 1\n",
    "        \n",
    "        tracker = self.unknown_person_tracker[person_id]\n",
    "        current_time = time.time()\n",
    "        time_present = current_time - tracker['first_seen']\n",
    "        \n",
    "        tracker['last_seen'] = current_time\n",
    "        tracker['appearances'] += 1\n",
    "        \n",
    "        # Determine escalation based on time present\n",
    "        if time_present > 120:  # 2 minutes\n",
    "            new_level = 3\n",
    "        elif time_present > 60:  # 1 minute\n",
    "            new_level = 2\n",
    "        else:\n",
    "            new_level = 1\n",
    "            \n",
    "        # Only escalate if level increases\n",
    "        if new_level > tracker['escalation_level']:\n",
    "            tracker['escalation_level'] = new_level\n",
    "            tracker['response_cooldown'] = [30, 45, 60][new_level - 1]\n",
    "            \n",
    "        return tracker['escalation_level']\n",
    "    \n",
    "    def _update_situation_context(self):\n",
    "        \"\"\"Update dynamic context for better responses\"\"\"\n",
    "        hour = datetime.now().hour\n",
    "        if 5 <= hour < 12:\n",
    "            time_desc = \"morning\"\n",
    "        elif 12 <= hour < 18:\n",
    "            time_desc = \"afternoon\" \n",
    "        else:\n",
    "            time_desc = \"evening\"\n",
    "        \n",
    "        self.situation_context['time_of_day'] = time_desc\n",
    "\n",
    "    def _format_conversation_history(self, history):\n",
    "        \"\"\"Format conversation history for LLM\"\"\"\n",
    "        if not history:\n",
    "            return \"No previous conversation\"\n",
    "        return \"\\n\".join([f\"{speaker}: {text}\" for speaker, text in history])\n",
    "\n",
    "    def _get_fallback_response(self, escalation_level):\n",
    "        \"\"\"Fallback responses when LLM fails\"\"\"\n",
    "        fallbacks = {\n",
    "            1: \"Hello, who are you and what are you doing here?\",\n",
    "            2: \"I need you to leave this area immediately.\",\n",
    "            3: \"Final warning! Security is being notified. Leave now!\"\n",
    "        }\n",
    "        return fallbacks.get(escalation_level, \"Please identify yourself.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def setup_llm(self):\n",
    "        try:\n",
    "            api_key = os.getenv('GEMINI_API_KEY')\n",
    "            genai.configure(api_key=api_key)\n",
    "            self.llm_model = genai.GenerativeModel('gemini-pro')\n",
    "            print(\"Gemini LLM configured\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error setting up LLM: {e}\")\n",
    "\n",
    "    def generate_escalation_response(self, escalation_level, person_id=0, context=\"\"):\n",
    "        \"\"\"Context-aware response generation with memory\"\"\"\n",
    "        # Update situation context\n",
    "        self._update_situation_context()\n",
    "        \n",
    "        # Get conversation history for this person\n",
    "        history = self.conversation_memory.get(person_id, [])\n",
    "        recent_history = history[-3:]  # Last 3 exchanges\n",
    "        \n",
    "        dynamic_prompt = f\"\"\"\n",
    "        You are an AI room guard agent. Current situation:\n",
    "        - Time: {self.situation_context['time_of_day']}\n",
    "        - Escalation level: {escalation_level}/3\n",
    "        - Additional context: {context}\n",
    "        \n",
    "        Recent conversation with this person:\n",
    "        {self._format_conversation_history(recent_history)}\n",
    "        \n",
    "        Generate a {['polite inquiry', 'firm warning', 'final alert'][escalation_level-1]}.\n",
    "        Be concise (1-2 sentences), direct, and appropriate for the escalation level.\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            if self.llm_model:\n",
    "                response = self.llm_model.generate_content(dynamic_prompt)\n",
    "                response_text = response.text.strip()\n",
    "            else:\n",
    "                response_text = self._get_fallback_response(escalation_level)\n",
    "            \n",
    "            # Store in conversation memory\n",
    "            if person_id not in self.conversation_memory:\n",
    "                self.conversation_memory[person_id] = []\n",
    "            self.conversation_memory[person_id].append((\"Guard\", response_text))\n",
    "            \n",
    "            return response_text\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"LLM error: {e}\")\n",
    "            return self._get_fallback_response(escalation_level)\n",
    "    def activate_alarm_protocol(self):\n",
    "        \"\"\"Real alarm functionality for level 3 escalation\"\"\"\n",
    "        if self.alarm_activated:\n",
    "            return\n",
    "            \n",
    "        self.alarm_activated = True\n",
    "        \n",
    "        # Visual alarm\n",
    "        alarm_thread = threading.Thread(target=self._flash_alarm, daemon=True)\n",
    "        alarm_thread.start()\n",
    "        \n",
    "        # Audio alarm\n",
    "        self.speak(\"INTRUDER ALERT! Security has been notified! Leave immediately!\")\n",
    "        \n",
    "        # Notify authorities\n",
    "        self.notify_authorities()\n",
    "        \n",
    "        print(\"ALARM ACTIVATED - Authorities notified\")\n",
    "\n",
    "    def _flash_alarm(self):\n",
    "        \"\"\"Visual alarm display\"\"\"\n",
    "        while self.alarm_activated and self.guard_mode:\n",
    "            # Create flashing alert window\n",
    "            for color in [(0, 0, 255), (0, 0, 0)]:  # Red, Black\n",
    "                alert_frame = np.zeros((200, 600, 3), dtype=np.uint8)\n",
    "                alert_frame[:] = color\n",
    "                \n",
    "                cv2.putText(alert_frame, \"INTRUDER ALERT!\", (50, 100),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 3)\n",
    "                cv2.imshow(\"ALERT - INTRUDER DETECTED\", alert_frame)\n",
    "                cv2.waitKey(500)  # Flash every 500ms\n",
    "                \n",
    "        cv2.destroyWindow(\"ALERT - INTRUDER DETECTED\")\n",
    "\n",
    "    def notify_authorities(self):\n",
    "        \"\"\"Actually notify security/authorities\"\"\"\n",
    "        try:\n",
    "            # Save alert to file (always works)\n",
    "            with open(\"intruder_alert.log\", \"a\") as f:\n",
    "                f.write(f\"Alert at {datetime.now()}: Unknown person detected - Level 3 escalation\\n\")\n",
    "            \n",
    "            print(\"Alert logged to intruder_alert.log\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Failed to notify authorities: {e}\")\n",
    "\n",
    "\n",
    "    def handle_unknown_person(self, face_encoding, frame):\n",
    "        \"\"\"Complete unknown person handling with escalation\"\"\"\n",
    "        person_id = self._find_or_create_person_id(face_encoding[0] if isinstance(face_encoding, list) else face_encoding)\n",
    "        \n",
    "        # Update tracking and get escalation level\n",
    "        escalation_level = self._update_person_tracking(person_id, face_encoding)\n",
    "        \n",
    "        current_time = time.time()\n",
    "        tracker = self.unknown_person_tracker[person_id]\n",
    "        \n",
    "        # Check if enough time has passed for next interaction\n",
    "        if current_time - tracker['last_interaction'] > tracker['response_cooldown']:\n",
    "            context = f\"Person detected {tracker['appearances']} times, present for {int(current_time - tracker['first_seen'])} seconds\"\n",
    "            response = self.generate_escalation_response(escalation_level, person_id, context)\n",
    "            \n",
    "            self.speak(response)\n",
    "            print(f\"Level {escalation_level}: {response}\")\n",
    "            \n",
    "            # Activate alarm for level 3\n",
    "            if escalation_level == 3:\n",
    "                self.activate_alarm_protocol()\n",
    "            \n",
    "            tracker['last_interaction'] = current_time\n",
    "\n",
    "    def _find_matching_person(self,encoding,threshold=0.1):\n",
    "        for person_id, data in self.unknown_person_tracker.items():\n",
    "            stored_encoding = data['reference_encoding']\n",
    "            distance = np.linalg.norm(stored_encoding - encoding)\n",
    "            if distance < threshold:\n",
    "                return person_id\n",
    "        return None \n",
    " \n",
    "    \n",
    "\n",
    "\n",
    "    def speak(self,text):\n",
    "        self.tts_engine.say(text)\n",
    "        self.tts_engine.runAndWait()\n",
    "    \n",
    "    \n",
    "    \n",
    "    def enroll_using_webcam(self,name=\"unknown\"):\n",
    "        self.camera=cv2.VideoCapture(0)\n",
    "        self.speak(f\"Please look at the camera for face enrollment as {name}\")\n",
    "\n",
    "        enrollment_frames = []\n",
    "        frames_captured = 0\n",
    "        max_frames = 10\n",
    "        \n",
    "        while frames_captured < max_frames:\n",
    "            ret, frame = self.camera.read()\n",
    "            if not ret:\n",
    "                print(\" Failed to capture frame\")\n",
    "                continue\n",
    "            \n",
    "            # Convert BGR to RGB\n",
    "            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Find all face locations and encodings in the current frame\n",
    "            face_locations = face_recognition.face_locations(rgb_frame)\n",
    "            face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "            \n",
    "            if len(face_encodings) == 1:\n",
    "                enrollment_frames.append(face_encodings[0])\n",
    "                frames_captured += 1\n",
    "                print(f\" Captured face frame {frames_captured}/{max_frames}\")\n",
    "                \n",
    "                # Show preview\n",
    "                cv2.putText(frame, f\"Enrolling: {frames_captured}/{max_frames}\", \n",
    "                           (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "            \n",
    "            cv2.imshow(\"Face Enrollment - Press 'q' to cancel\", frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "            \n",
    "            time.sleep(0.5)  # Wait between captures\n",
    "        \n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "        if enrollment_frames:\n",
    "            # Average the encodings for better accuracy\n",
    "            avg_encoding = np.mean(enrollment_frames, axis=0)\n",
    "            self.known_face_encodings.append(avg_encoding)\n",
    "            self.known_face_names.append(name)\n",
    "            self.save_trusted_faces()\n",
    "            self.speak(f\"Successfully enrolled {name} as a trusted person\")\n",
    "            return True\n",
    "        else:\n",
    "            self.speak(\"Failed to capture face. Please try again.\")\n",
    "            return False\n",
    "        \n",
    "    def mic_stream(self):\n",
    "        \"\"\"Capture microphone audio in chunks\"\"\"\n",
    "        def callback(indata, frames, time, status):\n",
    "            if status:\n",
    "                print(f\"Audio status: {status}\")\n",
    "            self.audio_queue.put(indata.copy())\n",
    "        \n",
    "        with sd.InputStream(\n",
    "            samplerate=self.SAMPLE_RATE, \n",
    "            channels=1, \n",
    "            dtype='int16', \n",
    "            callback=callback,\n",
    "            blocksize=int(self.SAMPLE_RATE * self.CHUNK_SECONDS)\n",
    "        ):\n",
    "            while not self.stop_flag:\n",
    "                time.sleep(0.1)\n",
    "\n",
    "\n",
    "    def check_activation_command(self, text):\n",
    "        \"\"\"Check if text contains any activation phrase\"\"\"\n",
    "        return any(phrase in text for phrase in self.activation_phrases)\n",
    "    \n",
    "    def check_deactivation_command(self, text):\n",
    "        \"\"\"Check if text contains any deactivation phrase\"\"\"\n",
    "        return any(phrase in text for phrase in self.deactivation_phrases)\n",
    "    \n",
    "    def check_enrollment_command(self, text):\n",
    "        \"\"\"Check if text contains face enrollment phrase\"\"\"\n",
    "        return any(phrase in text for phrase in self.enrollment_phrases)\n",
    "    \n",
    "    def activate_guard_mode(self):\n",
    "        \"\"\"Activate guard mode with voice confirmation\"\"\"\n",
    "        with self.thread_lock:\n",
    "            self.guard_mode = True\n",
    "            self.unknown_person_tracker = {}\n",
    "            self.conversation_memory = {}\n",
    "            self.alarm_activated = False\n",
    "        \n",
    "        self.speak(\"Guard mode activated! Starting face monitoring.\")\n",
    "        print(f\"Guard mode ACTIVATED at {datetime.now().strftime('%H:%M:%S')}\")\n",
    "        \n",
    "        face_thread = threading.Thread(target=self.face_monitoring_loop, daemon=True)\n",
    "        face_thread.start()\n",
    "\n",
    "    \n",
    "    def deactivate_guard_mode(self):\n",
    "        \"\"\"Deactivate guard mode with voice confirmation\"\"\"\n",
    "        with self.thread_lock:\n",
    "            self.guard_mode = False\n",
    "            self.alarm_activated = False\n",
    "        \n",
    "        self.speak(\"Guard mode deactivated. Goodbye!\")\n",
    "        print(f\"Guard mode DEACTIVATED at {datetime.now().strftime('%H:%M:%S')}\")\n",
    "\n",
    "\n",
    "    def process_audio_chunk(self, chunk):\n",
    "        \"\"\"Process audio chunk with Whisper and handle commands\"\"\"\n",
    "        with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as tmp:\n",
    "            path = tmp.name\n",
    "        \n",
    "        try:\n",
    "            wv(path, self.SAMPLE_RATE, chunk)\n",
    "            result = self.model.transcribe(\n",
    "                path, \n",
    "                language=\"en\", \n",
    "                fp16=False, \n",
    "                condition_on_previous_text=False\n",
    "            )\n",
    "            \n",
    "            text = (result.get(\"text\") or \"\").strip().lower()\n",
    "            \n",
    "            if text:\n",
    "                print(f\"Heard: {text}\")\n",
    "                \n",
    "                # Check for various commands\n",
    "                if self.check_activation_command(text) and not self.guard_mode:\n",
    "                    self.activate_guard_mode()\n",
    "                elif self.check_deactivation_command(text) and self.guard_mode:\n",
    "                    self.deactivate_guard_mode()\n",
    "                elif self.check_enrollment_command(text):\n",
    "                    self.speak(\"Starting face enrollment process.\")\n",
    "                    self.enroll_using_webcam()\n",
    "                elif \"how many trusted\" in text or \"list trusted\" in text:\n",
    "                    count = len(self.known_face_names)\n",
    "                    if count == 0:\n",
    "                        self.speak(\"No trusted faces enrolled yet.\")\n",
    "                    else:\n",
    "                        self.speak(f\"I have {count} trusted faces enrolled.\")\n",
    "                        print(f\"Trusted faces: {', '.join(self.known_face_names)}\")\n",
    "                elif self.guard_mode:\n",
    "                    print(f\" In guard mode, heard: {text}\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing audio: {e}\")\n",
    "        finally:\n",
    "            if os.path.exists(path):\n",
    "                os.remove(path)\n",
    "    \n",
    " \n",
    "    def recognize(self,frame):\n",
    "        if not self.known_face_encodings:\n",
    "            return [],[]\n",
    "        \n",
    "        # convert to rgb \n",
    "        frame=cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "        #find faces and then make encoding to store\n",
    "        face_locations=face_recognition.face_locations(frame)\n",
    "        face_encodings=face_recognition.face_encodings(frame,face_locations)\n",
    "        recognized_names=[]\n",
    "        recognized_status=[]\n",
    "        for item in face_encodings:\n",
    "            matches=face_recognition.compare_faces(self.known_face_encodings,item,tolerance=0.5)\n",
    "\n",
    "            name=\"unknown\"\n",
    "            status=\"unknown\"\n",
    "            face_distances=face_recognition.face_distance(self.known_face_encodings,item)\n",
    "            best_match_index=np.argmin(face_distances) if len(face_distances)>0 else None\n",
    "\n",
    "            if matches[best_match_index]:\n",
    "                name=self.known_face_names[best_match_index]\n",
    "                status=\"trusted\"\n",
    "\n",
    "            recognized_names.append(name)\n",
    "            recognized_status.append(status)\n",
    "\n",
    "        return recognized_names,recognized_status,face_encodings\n",
    "    \n",
    "    \n",
    "    def face_monitoring_loop(self):\n",
    "        camera = self.get_camera()\n",
    "        \n",
    "        if not camera or not camera.isOpened():\n",
    "            self.speak(\"Error accessing the webcam for face monitoring.\")\n",
    "            print(\"Error: Could not open webcam.\")\n",
    "            self.guard_mode = False\n",
    "            return\n",
    "        \n",
    "        self.speak(\"Face monitoring started. Scanning for trusted individuals.\")\n",
    "        last_announcement = {}\n",
    "        announcement_cd = 30\n",
    "\n",
    "        while self.guard_mode and not self.stop_flag:\n",
    "            ret, frame = camera.read()\n",
    "            if not ret:\n",
    "                print(\"Failed to capture frame from webcam\")\n",
    "                time.sleep(1)\n",
    "                continue\n",
    "            \n",
    "            names, statuses, encodings = self.recognize(frame)\n",
    "            curr_t = time.time()\n",
    "            \n",
    "            for name, status, encoding in zip(names, statuses, encodings):\n",
    "                if status == \"trusted\":\n",
    "                    if name not in last_announcement or (curr_t - last_announcement[name]) > announcement_cd:\n",
    "                        self.speak(f\"Hello {name}, welcome back!\")\n",
    "                        print(f\" Recognized trusted person: {name}\")\n",
    "                        last_announcement[name] = curr_t\n",
    "                elif status == \"unknown\":\n",
    "                    # Only handle unknown person if not recently announced\n",
    "                    if \"unknown\" not in last_announcement or (curr_t - last_announcement[\"unknown\"]) > 10:\n",
    "                        self.handle_unknown_person(encoding, frame)\n",
    "                        last_announcement[\"unknown\"] = curr_t\n",
    "            \n",
    "            # Draw face boxes\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            face_locations = face_recognition.face_locations(frame_rgb)\n",
    "            \n",
    "            for (top, right, bottom, left), name, status in zip(face_locations, names, statuses):\n",
    "                color = (0, 255, 0) if status == \"trusted\" else (0, 0, 255)\n",
    "                cv2.rectangle(frame, (left, top), (right, bottom), color, 2)\n",
    "                cv2.putText(frame, f\"{name} ({status})\", (left, top - 10),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "            \n",
    "            cv2.imshow(\"AI Guard - Face Monitoring (Press 'q' to stop)\", frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        \n",
    "        cv2.destroyAllWindows()\n",
    "        print(\"Face monitoring stopped\")\n",
    "\n",
    "    \n",
    "\n",
    "  \n",
    "    def start_listening(self):\n",
    "        \"\"\"Start the continuous listening loop\"\"\"\n",
    "        self.listening = True\n",
    "        self.stop_flag = False\n",
    "        \n",
    "        # Start microphone stream in background thread\n",
    "        audio_thread = threading.Thread(target=self.mic_stream, daemon=True)\n",
    "        audio_thread.start()\n",
    "        \n",
    "        self.speak(\"AI Guard system ready. Say 'Guard my room' to activate or 'Enroll face' to add trusted persons.\")\n",
    "        print(\" Listening for commands...\")\n",
    "        print(f\" {len(self.known_face_names)} trusted faces loaded\")\n",
    "        \n",
    "        try:\n",
    "            while self.listening and not self.stop_flag:\n",
    "                if not self.audio_queue.empty():\n",
    "                    chunk = self.audio_queue.get()\n",
    "                    self.process_audio_chunk(chunk)\n",
    "                else:\n",
    "                    time.sleep(0.1)\n",
    "                    \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nShutting down AI Guard system...\")\n",
    "            self.stop_flag = True\n",
    "    \n",
    "    def stop_listening(self):\n",
    "        \"\"\"Stop the listening loop\"\"\"\n",
    "        self.listening = False\n",
    "        self.stop_flag = True\n",
    "        if self.camera:\n",
    "            self.camera.release()\n",
    "        cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a26dbcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face database found. Starting fresh.\n",
      "Gemini LLM configured\n",
      " Listening for commands...\n",
      " 0 trusted faces loaded\n",
      "Heard: oh\n",
      "Heard: have no\n",
      "Heard: i just feel free.\n",
      "Heard: lionsahah'll continue to keep their semi anfield south.\n",
      "Heard: it's in the middle one.\n",
      "Heard: it's about me.\n",
      "Heard: they did come with me cute and sharpening.\n",
      "Heard: appreciated the\n",
      "Heard: my room.\n",
      "Heard: i just wanted to make another sure for that...\n",
      "Heard: yes.\n",
      "Heard: guard my room.\n",
      "Guard mode ACTIVATED at 19:43:57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-554 (face_monitoring_loop):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\aj057\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\aj057\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"c:\\Users\\aj057\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\aj057\\AppData\\Local\\Temp\\ipykernel_78896\\4030875819.py\", line 534, in face_monitoring_loop\n",
      "ValueError: not enough values to unpack (expected 3, got 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heard: yeah.\n",
      " In guard mode, heard: yeah.\n",
      "Heard: yeah\n",
      " In guard mode, heard: yeah\n",
      "Heard: please want to bring movement to...\n",
      " In guard mode, heard: please want to bring movement to...\n",
      "Heard: so, it just happened to you.\n",
      " In guard mode, heard: so, it just happened to you.\n",
      "Heard: please, monitoring will come ahead.\n",
      " In guard mode, heard: please, monitoring will come ahead.\n",
      "Heard: recognize is returning.\n",
      " In guard mode, heard: recognize is returning.\n",
      "Heard: i don't know what you're expecting.\n",
      " In guard mode, heard: i don't know what you're expecting.\n",
      "Heard: it's an error that goes with the paryngate system.\n",
      " In guard mode, heard: it's an error that goes with the paryngate system.\n",
      "Heard: even if it's only 3000 feet.\n",
      " In guard mode, heard: even if it's only 3000 feet.\n",
      "Heard: here return the ting to the gara.\n",
      " In guard mode, heard: here return the ting to the gara.\n",
      "\n",
      "Shutting down AI Guard system...\n"
     ]
    }
   ],
   "source": [
    "guard=AIGuardAgent()\n",
    "guard.start_listening()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
