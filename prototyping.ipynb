{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd843b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aj057\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\face_recognition_models\\__init__.py:7: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_filename\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import queue,threading,time\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import write as wv\n",
    "import tempfile,os\n",
    "import sounddevice as sd\n",
    "import pyttsx3\n",
    "from datetime import datetime \n",
    "import pickle \n",
    "import face_recognition\n",
    "import cv2\n",
    "from pathlib import Path \n",
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "import requests,json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "289b575f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=whisper.load_model(\"base.en\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e06be592",
   "metadata": {},
   "outputs": [],
   "source": [
    "threading.Thread(target=mic_stream, daemon=True).start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dfda41d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61ec6ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AIGuardAgent:\n",
    "    def __init__(self):\n",
    "        self.model=whisper.load_model(\"base.en\")\n",
    "        self.SAMPLE_RATE=16000\n",
    "        self.CHUNK_SECONDS=2\n",
    "        self.audio_queue=queue.Queue()\n",
    "\n",
    "        self.tts_engine=pyttsx3.init()\n",
    "        self.tts_engine.setProperty('rate',150)\n",
    "\n",
    "        self.guard_mode=False\n",
    "        self.listening=False\n",
    "        self.stop_flag=False\n",
    "\n",
    "        self.face_db_path = \"FACE_DB_PATH\"#fill this in later \n",
    "        self.load_trusted_faces()\n",
    "    \n",
    "        self.activation_phrases = [\n",
    "            \"guard my room\",\n",
    "            \"protect my room\", \n",
    "            \"secure my room\",\n",
    "            \"start guard mode\",\n",
    "            \"activate guard\"\n",
    "        ]\n",
    "        self.deactivation_phrases = [\n",
    "            \"stop guard mode\",\n",
    "            \"deactivate guard\",\n",
    "            \"stand down\",\n",
    "            \"stop monitoring\",\n",
    "            \"goodbye guard\"\n",
    "        ]\n",
    "        self.enrollment_phrases = [\n",
    "            \"enroll face\",\n",
    "            \"register face\",\n",
    "            \"add trusted person\"\n",
    "        ]\n",
    "    \n",
    "    def speak(self,text):\n",
    "        self.tts_engine.say(text)\n",
    "        self.tts_engine.runAndWait()\n",
    "    \n",
    "    def load_trusted_faces(self):\n",
    "\n",
    "        if os.path.exists(self.face_db_path):\n",
    "            with open(self.face_db_path,'rb') as f:\n",
    "                data=pickle.load(f)#depends on what type of file me useing for the db i guess\n",
    "                self.known_face_encodings=data['encodings']\n",
    "                self.known_face_names=data['names']\n",
    "            print(f\"Loaded {len(self.known_face_names)} trusted faces.\")\n",
    "\n",
    "        else:\n",
    "            print(\"No existing faces database found. Starting fresh.\")\n",
    "            self.known_face_encodings=[]\n",
    "            self.known_face_names=[]\n",
    "\n",
    "    def save_trusted_faces(self):\n",
    "        with open(self.face_db_path,'wb') as f:  \n",
    "            pickle.dump({'encodings':self.known_face_encodings,'names':self.known_face_names},f)\n",
    "\n",
    "            print(\"Saved face to db\")\n",
    "\n",
    "    def enroll_using_webcam(self,name=\"unknown\"):\n",
    "        self.camera=cv2.VideoCapture(0)\n",
    "        self.speak(f\"Please look at the camera for face enrollment as {name}\")\n",
    "\n",
    "        enrollment_frames = []\n",
    "        frames_captured = 0\n",
    "        max_frames = 30\n",
    "        \n",
    "        while frames_captured < max_frames:\n",
    "            ret, frame = self.camera.read()\n",
    "            if not ret:\n",
    "                print(\" Failed to capture frame\")\n",
    "                continue\n",
    "            \n",
    "            # Convert BGR to RGB\n",
    "            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Find all face locations and encodings in the current frame\n",
    "            face_locations = face_recognition.face_locations(rgb_frame)\n",
    "            face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "            \n",
    "            if len(face_encodings) == 1:\n",
    "                enrollment_frames.append(face_encodings[0])\n",
    "                frames_captured += 1\n",
    "                print(f\" Captured face frame {frames_captured}/{max_frames}\")\n",
    "                \n",
    "                # Show preview\n",
    "                cv2.putText(frame, f\"Enrolling: {frames_captured}/{max_frames}\", \n",
    "                           (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "            \n",
    "            cv2.imshow(\"Face Enrollment - Press 'q' to cancel\", frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "            \n",
    "            time.sleep(0.5)  # Wait between captures\n",
    "        \n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "        if enrollment_frames:\n",
    "            # Average the encodings for better accuracy\n",
    "            avg_encoding = np.mean(enrollment_frames, axis=0)\n",
    "            self.known_face_encodings.append(avg_encoding)\n",
    "            self.known_face_names.append(name)\n",
    "            self.save_trusted_faces()\n",
    "            self.speak(f\"Successfully enrolled {name} as a trusted person\")\n",
    "            return True\n",
    "        else:\n",
    "            self.speak(\"Failed to capture face. Please try again.\")\n",
    "            return False\n",
    "        \n",
    "    def mic_stream(self):\n",
    "        \"\"\"Capture microphone audio in chunks\"\"\"\n",
    "        def callback(indata, frames, time, status):\n",
    "            if status:\n",
    "                print(f\"Audio status: {status}\")\n",
    "            self.audio_queue.put(indata.copy())\n",
    "        \n",
    "        with sd.InputStream(\n",
    "            samplerate=self.SAMPLE_RATE, \n",
    "            channels=1, \n",
    "            dtype='int16', \n",
    "            callback=callback,\n",
    "            blocksize=int(self.SAMPLE_RATE * self.CHUNK_SECONDS)\n",
    "        ):\n",
    "            while not self.stop_flag:\n",
    "                time.sleep(0.1)\n",
    "\n",
    "\n",
    "    def check_activation_command(self, text):\n",
    "        \"\"\"Check if text contains any activation phrase\"\"\"\n",
    "        return any(phrase in text for phrase in self.activation_phrases)\n",
    "    \n",
    "    def check_deactivation_command(self, text):\n",
    "        \"\"\"Check if text contains any deactivation phrase\"\"\"\n",
    "        return any(phrase in text for phrase in self.deactivation_phrases)\n",
    "    \n",
    "    def check_enrollment_command(self, text):\n",
    "        \"\"\"Check if text contains face enrollment phrase\"\"\"\n",
    "        return any(phrase in text for phrase in self.enrollment_phrases)\n",
    "    \n",
    "    def activate_guard_mode(self):\n",
    "        \"\"\"Activate guard mode with voice confirmation\"\"\"\n",
    "        self.guard_mode = True\n",
    "        self.speak(\"Guard mode activated! Starting face monitoring.\")\n",
    "        print(f\"Guard mode ACTIVATED at {datetime.now().strftime('%H:%M:%S')}\")\n",
    "        \n",
    "        # Start face monitoring in a separate thread\n",
    "        face_thread = threading.Thread(target=self.face_monitoring_loop, daemon=True)\n",
    "        face_thread.start()\n",
    "    \n",
    "    def deactivate_guard_mode(self):\n",
    "        \"\"\"Deactivate guard mode with voice confirmation\"\"\"\n",
    "        self.guard_mode = False\n",
    "        self.speak(\"Guard mode deactivated. Goodbye!\")\n",
    "        print(f\"Guard mode DEACTIVATED at {datetime.now().strftime('%H:%M:%S')}\")\n",
    "    def process_audio_chunk(self, chunk):\n",
    "        \"\"\"Process audio chunk with Whisper and handle commands\"\"\"\n",
    "        with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as tmp:\n",
    "            path = tmp.name\n",
    "        \n",
    "        try:\n",
    "            wv(path, self.SAMPLE_RATE, chunk)\n",
    "            result = self.model.transcribe(\n",
    "                path, \n",
    "                language=\"en\", \n",
    "                fp16=False, \n",
    "                condition_on_previous_text=False\n",
    "            )\n",
    "            \n",
    "            text = (result.get(\"text\") or \"\").strip().lower()\n",
    "            \n",
    "            if text:\n",
    "                print(f\"Heard: {text}\")\n",
    "                \n",
    "                # Check for various commands\n",
    "                if self.check_activation_command(text) and not self.guard_mode:\n",
    "                    self.activate_guard_mode()\n",
    "                elif self.check_deactivation_command(text) and self.guard_mode:\n",
    "                    self.deactivate_guard_mode()\n",
    "                elif self.check_enrollment_command(text):\n",
    "                    self.speak(\"Starting face enrollment process.\")\n",
    "                    self.enroll_using_webcam()\n",
    "                elif \"how many trusted\" in text or \"list trusted\" in text:\n",
    "                    count = len(self.known_face_names)\n",
    "                    if count == 0:\n",
    "                        self.speak(\"No trusted faces enrolled yet.\")\n",
    "                    else:\n",
    "                        self.speak(f\"I have {count} trusted faces enrolled.\")\n",
    "                        print(f\"Trusted faces: {', '.join(self.known_face_names)}\")\n",
    "                elif self.guard_mode:\n",
    "                    print(f\" In guard mode, heard: {text}\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing audio: {e}\")\n",
    "        finally:\n",
    "            if os.path.exists(path):\n",
    "                os.remove(path)\n",
    "    \n",
    " \n",
    "    def recognize(self,frame):\n",
    "        if not self.known_face_encodings:\n",
    "            return [],[]\n",
    "        \n",
    "        # convert to rgb \n",
    "        frame=cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "        #find faces and then make encoding to store\n",
    "        face_locations=face_recognition.face_locations(frame)\n",
    "        face_encodings=face_recognition.face_encodings(frame,face_locations)\n",
    "        recognized_names=[]\n",
    "        recognized_status=[]\n",
    "        for item in face_encodings:\n",
    "            matches=face_recognition.compare_faces(self.known_face_encodings,item,tolerance=0.5)\n",
    "\n",
    "            name=\"unknown\"\n",
    "            status=\"unknown\"\n",
    "            face_distances=face_recognition.face_distance(self.known_face_encodings,item)\n",
    "            best_match_index=np.argmin(face_distances) if len(face_distances)>0 else None\n",
    "\n",
    "            if matches[best_match_index]:\n",
    "                name=self.known_face_names[best_match_index]\n",
    "                status=\"trusted\"\n",
    "\n",
    "            recognized_names.append(name)\n",
    "            recognized_status.append(status)\n",
    "\n",
    "        return recognized_names,recognized_status\n",
    "    def face_monitoring_loop(self):\n",
    "        if not self.camera:\n",
    "            self.camera = cv2.VideoCapture(0)\n",
    "        \n",
    "        if not self.camera.isOpened():\n",
    "            self.speak(\"Error accessing the webcam for face monitoring.\")\n",
    "            print(\"Error: Could not open webcam.\")\n",
    "            self.guard_mode = False\n",
    "            return\n",
    "        \n",
    "        self.speak(\"Face monitoring started. Scanning for trusted individuals.\")\n",
    "\n",
    "        last_announcement={}\n",
    "        announcement_cd=30\n",
    "\n",
    "        while self.guard_mode and not self.stop_flag:\n",
    "            ret,frame=self.camera.read()\n",
    "\n",
    "            if not ret:\n",
    "                print(\"Failed to capture frame from webcam\")\n",
    "                #sleep a bit to not overload\n",
    "                time.sleep(1)\n",
    "                continue\n",
    "            \n",
    "            names,stati=self.recognize(frame)\n",
    "\n",
    "            curr_t=time.time()\n",
    "            for name,status in zip(names,stati):\n",
    "                if status==\"trusted\":\n",
    "                    if name not in last_announcement or (curr_t - last_announcement[name]) > announcement_cd:\n",
    "                        self.speak(f\"Hello {name}, welcome back!\")\n",
    "                        print(f\" Recognized trusted person: {name}\")\n",
    "                        last_announcement[name]=curr_t\n",
    "                else:\n",
    "                    if \"unknown\" not in last_announcement or (curr_t - last_announcement[\"unknown\"]) > announcement_cd:\n",
    "                        self.speak(\"Alert! Unknown person detected!\")\n",
    "                        print(\" Alert! Unknown person detected!\")\n",
    "                        last_announcement[\"unknown\"]=curr_t\n",
    "            if len(names) > 0:\n",
    "                for (top, right, bottom, left), name, status in zip(\n",
    "                    face_recognition.face_locations(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)), \n",
    "                    names, stati\n",
    "                ):\n",
    "                    color = (0, 255, 0) if status == \"trusted\" else (0, 0, 255)\n",
    "                    cv2.rectangle(frame, (left, top), (right, bottom), color, 2)\n",
    "                    cv2.putText(frame, f\"{name} ({status})\", (left, top - 10),\n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "            \n",
    "            cv2.imshow(\"AI Guard - Face Monitoring (Press 'q' to stop)\", frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "            \n",
    "            #time.sleep(0.1) uncomment if your cpu dies. We run a ppt then\n",
    "        \n",
    "        cv2.destroyAllWindows()#stop\n",
    "        print(\"Face monitoring stopped\")\n",
    "    \n",
    "\n",
    "  \n",
    "    def start_listening(self):\n",
    "        \"\"\"Start the continuous listening loop\"\"\"\n",
    "        self.listening = True\n",
    "        self.stop_flag = False\n",
    "        \n",
    "        # Start microphone stream in background thread\n",
    "        audio_thread = threading.Thread(target=self.mic_stream, daemon=True)\n",
    "        audio_thread.start()\n",
    "        \n",
    "        self.speak(\"AI Guard system ready. Say 'Guard my room' to activate or 'Enroll face' to add trusted persons.\")\n",
    "        print(\" Listening for commands...\")\n",
    "        print(f\" {len(self.known_face_names)} trusted faces loaded\")\n",
    "        \n",
    "        try:\n",
    "            while self.listening and not self.stop_flag:\n",
    "                if not self.audio_queue.empty():\n",
    "                    chunk = self.audio_queue.get()\n",
    "                    self.process_audio_chunk(chunk)\n",
    "                else:\n",
    "                    time.sleep(0.1)\n",
    "                    \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nShutting down AI Guard system...\")\n",
    "            self.stop_flag = True\n",
    "    \n",
    "    def stop_listening(self):\n",
    "        \"\"\"Stop the listening loop\"\"\"\n",
    "        self.listening = False\n",
    "        self.stop_flag = True\n",
    "        if self.camera:\n",
    "            self.camera.release()\n",
    "        cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a26dbcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No existing faces database found. Starting fresh.\n",
      " Listening for commands...\n",
      " 0 trusted faces loaded\n",
      "Heard: register face.\n",
      "Heard: okay, i'm an open gift.\n",
      "Heard: well, you will know that\n",
      "Heard: and\n",
      "Heard: i have to take it. it works.\n",
      "Heard: a consequence.\n",
      "Heard: but it may or may not be there into. okay? how about cass' tail? oh, that's great.\n",
      "Heard: find my room. bled in check.\n",
      "Heard: find myut paul glensity\n",
      "\n",
      "Shutting down AI Guard system...\n"
     ]
    }
   ],
   "source": [
    "guard=AIGuardAgent()\n",
    "guard.start_listening()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
